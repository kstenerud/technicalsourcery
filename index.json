[{"categories":["encoding"],"content":"QR codes have replaced bar codes in many places because they can store a lot more information, but this advantage is limited by the fact that they can only store textual data and have no inherent structure. In this post, I\u0026rsquo;ll demonstrate how to overcome these limitations and give QR codes superpowers!\nQR Codes and Their Limitations QR codes were invented by the Japanese company Denso Wave in the mid-90s as a way to get higher information density in machine-readable optical labels. They support a number of encoding methods including numeric digits, alphanumerics, kanji, and raw text. Although the QR format does have an encoding called \u0026ldquo;byte mode\u0026rdquo;, each byte in this mode represents an ISO 8859-1 character, not binary data.\nECI escape sequences allow encoding of nonstandard text encodings, but each escape code bloats the message with out-of-band data (they have to be long in order to minimize the chance of misinterpreting data as escapes), and still binary data is not supported üòû\nIf you did try to write binary data, it would likely just end up garbled once a reader tries to interpret it as text (some decoders apply heuristics to guess at the intended format, complicating things even further). So there\u0026rsquo;s no reliable way to directly encode binary data into a QR code, let alone ad-hoc structured binary data.\n\u0026hellip; Or is there? With a little creative thinking, some minor algorithmic tweaks and the Concise Encoding format , it\u0026rsquo;s possible to work around this limitation to reliably read and write binary ad-hoc structured data in QR codes!\nTo see how, let\u0026rsquo;s take a look at the text encoding used for \u0026ldquo;byte mode\u0026rdquo;: ISO 8859-1.\n    x0 x1 x2 x3 x4 x5 x6 x7 x8 x9 xA xB xC xD xE xF     0x                   1x                   2x SP ! \u0026quot; # $ % \u0026amp; ' ( ) * + , - . /   3x 0 1 2 3 4 5 6 7 8 9 : ; \u0026lt; = \u0026gt; ?   4x @ A B C D E F G H I J K L M N O   5x P Q R S T U V W X Y Z [ \\ ] ^ _   6x ` a b c d e f g h i j k l m n o   7x p q r s t u v w x y z {   } ~   8x                   9x                   Ax NBSP ¬° ¬¢ ¬£ ¬§ ¬• ¬¶ ¬ß ¬® ¬© ¬™ ¬´ ¬¨ SHY ¬Æ ¬Ø   Bx ¬∞ ¬± ¬≤ ¬≥ ¬¥ ¬µ ¬∂ ¬∑ ¬∏ ¬π ¬∫ ¬ª ¬º ¬Ω ¬æ ¬ø   Cx √Ä √Å √Ç √É √Ñ √Ö √Ü √á √à √â √ä √ã √å √ç √é √è   Dx √ê √ë √í √ì √î √ï √ñ √ó √ò √ô √ö √õ √ú √ù √û √ü   Ex √† √° √¢ √£ √§ √• √¶ √ß √® √© √™ √´ √¨ √≠ √Æ √Ø   Fx √∞ √± √≤ √≥ √¥ √µ √∂ √∑ √∏ √π √∫ √ª √º √Ω √æ √ø    Notice how the codes 00-1f and 7f-9f are unassigned (many text formats do this for legacy reasons). This means that any non-ECI data containing these values is invalid because it can\u0026rsquo;t be decoded as text.\nSide Note: Not all QR decoders actually validate this, which is why you sometimes get strange garbled results after decoding a QR code that was mistakenly encoded in UTF-8 without an ECI header.\nSo even though there are no technical limitations against using them, unassigned characters are considered invalid, which means that any valid QR code will not contain them.\nOr to put it another way: these characters are up for grabs!\nWhat we could do is re-purpose one of these unassigned characters and use it as a sentinel to indicate the presence of special, non-textual data. When a scanner that knows about the sentinel byte encounters it as the first byte of the payload, it can switch decoding modes reliably.\nEncoding ad-hoc binary data into QR codes Concise Encoding is an ad-hoc data format with a text and a binary encoding form. In the binary format (CBE) , all documents begin with the sentinel byte 0x83 (specifically chosen because it\u0026rsquo;s an invalid starting byte in most popular text formats, including ISO 8859 and UTF-8). We\u0026rsquo;ll leverage this to encode a CBE document into a QR code.\nI\u0026rsquo;ve adapted https://github.com/kstenerud/enctool to support QR codes and initiate special processing when the first byte of the QR data is 0x83. You can follow along by installing the go language on your system and then installing enctool like so:\n1go install github.com/kstenerud/enctool@latest This will install enctool into $GOPATH/bin (usually go/bin in your home directory).\nWe\u0026rsquo;ll be using enctool\u0026rsquo;s convert functionality. You can see the available options by typing:\n1enctool convert -h Example As an example, let\u0026rsquo;s assume that we\u0026rsquo;re coming up with a new international shipping and storage requirements QR code format. We have an example document that we want to encode into a QR code. I\u0026rsquo;m writing it here in the text format (CTE ) for convenience, but the actual data will be written in the binary format (CBE ).\n1c1 { 2 \u0026#34;temperature range\u0026#34; = [-20 5] 3 \u0026#34;hazards\u0026#34; = [ 4 \u0026#34;pressurized\u0026#34; 5 \u0026#34;flammable\u0026#34; 6 \u0026#34;fragile\u0026#34; 7 ] 8 \u0026#34;max tilt degrees\u0026#34; = 15 9 \u0026#34;perishes after\u0026#34; = 2022-12-05 10} Save this document as with-text.cte, and then convert to CBE like so:\n1enctool convert -s with-text.cte -sf cte -df cbe -d with-text.cbe How big is it?\n1ls -l with-text.cbe 2-rw-rw-r-- 1 karl karl 105 Jan 6 17:15 with-text.cbe 105 bytes\u0026hellip; But that\u0026rsquo;s mainly due to the many text fields it contains. We could encode it as-is, but it would produce a pretty big QR code!\nWhat if instead we came up with a schema that replaces all well-known text keys and values with integer enumerations? For completeness sake we\u0026rsquo;ll also include a \u0026ldquo;fourCC\u0026rdquo; style identifier so that any reader can identify which schema and version the data was encoded with (let\u0026rsquo;s say that key 0 is always used to specify the schema).\nFictional Schema:\n 0 = schema ID and version adherence: (fourCC-style integer: \u0026ldquo;TSS\u0026rdquo; + version) 1 = temperature range: (list of two integers) 2 = hazards: (list of enumerated integers):  0 = corrosive 1 = photoreactive \u0026hellip; 4 = pressurized \u0026hellip; 6 = flammable \u0026hellip; 19 = fragile   \u0026hellip; 4 = max tilt degrees: (integer) \u0026hellip; 9 = perishes after: (date)  Document (CTE):\n1c1 { 2 0 = 0x54535301 // Transport and Storage Schema version 1 (\u0026#34;TSS\u0026#34; + 1) 3 1 = [-20 5] // Temperature range from -20 to 5 4 2 = [ // Hazards: 5 4 // Pressurized 6 6 // Flammable 7 19 // Fragile 8 ] 9 4 = 15 // Max 15 degrees tilt 10 9 = 2022-12-05 // Perishes after Dec 5, 2022 11} Because integers from -100 to 100 encode into a single byte in CBE, you can achieve tremendous space savings using them as enumerated types. Let\u0026rsquo;s try it with our modifications (saving this document as with-enums.cte):\n1enctool convert -s with-enums.cte -sf cte -df cbe -d with-enums.cbe Now how big is it?\n1ls -l with-enums.cbe 2-rw-rw-r-- 1 karl karl 28 Jan 6 17:22 with-enums.cbe We\u0026rsquo;ve shrunk down our payload from 105 bytes to 28 bytes! Much better!\nHere are the byte contents of the CBE document. Note the first byte 0x83, which is an unassigned character in ISO 8859-1:\n183 00 79 00 6c 01 53 53 54 01 7a ec 05 7b 02 7a 04 06 13 7b 04 0f 09 99 85 59 00 7b Now let\u0026rsquo;s encode this data into a QR code:\n1enctool convert -s with-enums.cte -sf cte -df qr -d qr.png -b 1 -is 400 Our QR code is in the newly created qr.png:\n Now let\u0026rsquo;s read the data back. I\u0026rsquo;ll convert it to CTE for convenience, printing to stdout:\n1enctool convert -s qr.png -sf qr -df cte Output:\n1c0 2{ 3 0 = 1414746881 4 1 = [ 5 -20 6 5 7 ] 8 2 = [ 9 4 10 6 11 19 12 ] 13 4 = 15 14 9 = 2022-12-05 15} Once we\u0026rsquo;ve got our document, we can process it through the schema to recover the true meaning of the data.\nSo there you have it: Supercharged QR codes that can hold arbitrary structured data! Neat!\n","date":"Jan 6, 2022","img":"https://www.technicalsourcery.net/images/thumbnails/qr-superpowers.png","permalink":"https://www.technicalsourcery.net/posts/qr-superpowers/","series":null,"tags":["encoding","qr-code","concise-encoding"],"title":"Giving QR Codes Superpowers"},{"categories":null,"content":"I\u0026rsquo;m Karl, a Canadian software developer by profession with a passion for open source. Over the years, I\u0026rsquo;ve built many systems that businesses and people depend upon, including:\n Current: Concise Encoding  2012: KSCrash (crash reporter for Apple devices) 2010: ObjectAL (audio library for Apple devices) 2006: HSE (MVC web component framework for Java) 1997: Musashi M680x0 emulator (used in MAME, Namco Classics, SNK Classics, etc) 1996: Ringconnectd (telephone ring knocking daemon) 1995: DOS serial library   I\u0026rsquo;ll likely continue innovating until my last breath. But I\u0026rsquo;m only one person, and there are only so many hours in a day.\n","date":"Nov 27, 2021","img":"","permalink":"https://www.technicalsourcery.net/about/","series":null,"tags":null,"title":"About Me"},{"categories":["virtualization"],"content":"NixOS has a lot of really cool ideas, but unfortunately installing on a VM is still tricky. This guide is designed as a \u0026ldquo;just get me something working, please!\u0026rdquo; way to get a headless NixOS install up and running in a libvirt VM.\nPrerequisites You will need to have libvirt and virt-install on your system.\nOn Ubuntu:\n1sudo apt update 2sudo apt install qemu-kvm libvirt-daemon-system virtinst On Redhat:\n1sudo yum install kvm virt-manager libvirt libvirt-python python-virtinst You\u0026rsquo;ll also need the NixOS minimal ISO image Launching the VM Use the following as an example for launching your vm, picking a decent place to create your qcow2 disk image (you will be installing to this) so that you can find it later:\n1virt-install --name=nixos \\ 2--memory=8196 \\ 3--vcpus=2 \\ 4--disk /path/to/my-nixos-disk-image.qcow2,device=disk,bus=virtio,size=16 \\ 5--cdrom=/path/to/latest-nixos-minimal-x86_64-linux.iso \\ 6--os-type=generic \\ 7--boot=uefi \\ 8--nographics \\ 9--console pty,target_type=virtio This launches a UEFI-enabled (--boot=uefi) headless (--nographics) VM named \u0026ldquo;nixos\u0026rdquo; (--name=nixos) with 8 GB of RAM (--memory=8192), 2 CPUs (--vcpus=2), and a disk image with 16GB of space (size=16). It also connects to the guest\u0026rsquo;s console (--console pty,target_type=virtio).\nNote: The --cdrom entry sets the ISO image to boot from once. After rebooting, it will boot from your qcow2 image instead.\nAfter launching the VM, it will sit here for awhile, looking like it\u0026rsquo;s stuck:\n1Starting install... 2Connected to domain nixos 3Escape character is ^] Just be patient; it should boot within a couple of minutes:\n1\u0026lt;\u0026lt;\u0026lt; Welcome to NixOS 21.05.1970.11c662074e2 (x86_64) - hvc0 \u0026gt;\u0026gt;\u0026gt; 2The \u0026#34;nixos\u0026#34; and \u0026#34;root\u0026#34; accounts have empty passwords. 3 4An ssh daemon is running. You then must set a password 5for either \u0026#34;root\u0026#34; or \u0026#34;nixos\u0026#34; with `passwd` or add an ssh key 6to /home/nixos/.ssh/authorized_keys be able to login. 7 8 9Run \u0026#39;nixos-help\u0026#39; for the NixOS manual. 10 11nixos login: nixos (automatic login) 12 13 14[nixos@nixos:~]$ Some tips before you continue There will invariably be problems, so here are some tips to help get you unstuck:\nExiting the console To exit the console, hold the CTRL key and press ], then press Enter.\nReconnecting to the console: To reconnect to the console, type virsh console nixos\nDeleting everything and starting over If everything gets completely broken, here\u0026rsquo;s how to start over fresh:\n Stop the VM by typing virsh destroy nixos (turns off the machine) Remove the domain by typing virsh undefine nixos --nvram (deletes the VM) If you want the disk image gone also, you must delete it manually (wherever you put my-nixos-disk-image.qcow2)  Accessing the VM from your host Use the virsh command to access the VM from the host. It\u0026rsquo;s a good idea to familiarize yourself with virsh .\n1$ virsh list 2 Id Name State 3----------------------- 4 13 nixos running Getting the guest\u0026rsquo;s IP address You can do this within the guest by typing ip a, or you can do it from the host side using virsh\u0026rsquo;s net-dhcp-leases command:\n1$ virsh net-dhcp-leases default 2 Expiry Time MAC address Protocol IP address Hostname Client ID or DUID 3----------------------------------------------------------------------------------------------------------------- 4 2021-07-23 21:04:31 52:54:00:33:0c:ee ipv4 192.168.111.206/24 nixos 01:52:54:00:33:0c:ee 5 Connecting to the installer via SSH The console can be a bit funny at times (especially if you resize your shell window), so it\u0026rsquo;s generally nicer to SSH in. We\u0026rsquo;ll use a password-based SSH login since it\u0026rsquo;s only the installer.\n Create a password (Note: This is only setting a temporary password for the installer, not the OS you are about to install):  1[nixos@nixos:~]$ passwd 2New password: 3Retype new password: 4passwd: password updated successfully Get the IP address:  1[nixos@nixos:~]$ ip a 2... 32: ens2: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 4... 5 inet 192.168.111.206/24 brd 192.168.111.255 scope global dynamic noprefixroute ens2 6... SSH in to the installer:  1$ ssh nixos@192.168.111.206 2Password: 3Last login: Sun Aug 1 05:39:07 2021 4 5[nixos@nixos:~]$ Installing NixOS Switch to root Doing the installation process as root makes it less cumbersome, and it\u0026rsquo;s safe since you can\u0026rsquo;t damage the installer ISO image:\n1[nixos@nixos:~]$ sudo su - 2 3[root@nixos:~]# Setup the disk This follows the example in the NixOS manual , except that your disk is /dev/vda.\n1parted --script /dev/vda -- mklabel gpt 2parted --script /dev/vda -- mkpart primary 512MiB -8GiB 3parted --script /dev/vda -- mkpart primary linux-swap -8GiB 100% 4parted --script /dev/vda -- mkpart ESP fat32 1MiB 512MiB 5parted --script /dev/vda -- set 3 esp on 6mkfs.ext4 -F -L nixos /dev/vda1 7mkswap -L swap /dev/vda2 8mkfs.fat -F 32 -n boot /dev/vda3 9mount /dev/disk/by-label/nixos /mnt 10mkdir -p /mnt/boot 11mount /dev/disk/by-label/boot /mnt/boot 12swapon /dev/vda2 13nixos-generate-config --root /mnt Customize your install At this point, you can customize your configuration before installing. Configuration happens via configuration.nix, and the default config comes with a number of commented-out suggestions. Normally, you\u0026rsquo;d keep your configuration files in a repository and copy them in to the machine being provisioned.\nTo edit your configuration:\n1[root@nixos:~]# nano /mnt/etc/nixos/configuration.nix Once you\u0026rsquo;re happy with your configuration, press CTRL-X and save the file to exit the editor.\nConfiguration: Add an admin user It\u0026rsquo;s a good idea to create an admin user for yourself because logging in as root is dangerous. Here\u0026rsquo;s an example user with admin privileges:\n1 users.users.myuser = { 2 isNormalUser = true; 3 home = \u0026#34;/home/myuser\u0026#34;; 4 description = \u0026#34;My example admin user\u0026#34;; 5 # wheel allows sudo, networkmanager allows network modifications 6 extraGroups = [ \u0026#34;wheel\u0026#34; \u0026#34;networkmanager\u0026#34; ]; 7 # For password login (works with console and SSH): 8 hashedPassword = \u0026#34;$6$Cc5l1Gyv2gP$Mw0RKFkH719QCZAggQDTJIDcE4HoHFEYUqS71H0FVA/AHR4BJEWhfyPaR3RKiz3WsMsDp1di4oPX3b1s3s6Jt.\u0026#34;; 9 # For SSH key login (works with SSH only): 10 openssh.authorizedKeys.keys = [ \u0026#34;ssh-dss AAAAB3Nza... myuser@foobar\u0026#34; ]; 11 }; hashedPassword can be generated using mkpasswd:\n1[root@nixos:~]# mkpasswd -m sha-512 2Password: 3$6$Cc5l1Gyv2gP$Mw0RKFkH719QCZAggQDTJIDcE4HoHFEYUqS71H0FVA/AHR4BJEWhfyPaR3RKiz3WsMsDp1di4oPX3b1s3s6Jt. Configuration: Enable SSH You can also turn on SSH so that you can connect via secure shell after rebooting (otherwise only the console will work):\n1 services.openssh.enable = true; Run the installer Once you\u0026rsquo;re happy with your configuration, it\u0026rsquo;s time to install the OS:\n1[root@nixos:~]# nixos-install If you\u0026rsquo;ve made any mistakes, it will print out error messages detailing what you need to fix in your configuration.nix.\nThe last installer step will ask you to set the root password (you can use nixos-install --no-root-passwd to disable this and leave it blank):\n1setting root password... 2Enter new UNIX password: *** 3Retype new UNIX password: *** Reboot This will cause it to reboot into your newly installed disk:\n1[root@nixos:~]# reboot 2 3Domain creation completed. 4Restarting guest. 5Connected to domain nixos 6Escape character is ^] 7 8 9\u0026lt;\u0026lt;\u0026lt; Welcome to NixOS 21.05.1970.11c662074e2 (x86_64) - hvc0 \u0026gt;\u0026gt;\u0026gt; 10 11Run \u0026#39;nixos-help\u0026#39; for the NixOS manual. 12 13nixos login: Log in as the admin user you created (or you can log in via SSH if you enbled it). If you need to make further changes to the configuration, edit /etc/nixos/configuration.nix and then build the new configuration:\n1nixos-rebuild switch At this point, you have a functional NixOS in a virtual machine. You\u0026rsquo;re at the equivalent of chapter 3 in the NixOS manual , and can now start configuring your OS .\nEnjoy!\n","date":"Aug 1, 2021","img":"https://www.technicalsourcery.net/images/thumbnails/nixos.png","permalink":"https://www.technicalsourcery.net/posts/nixos-in-libvirt/","series":null,"tags":["virtualization","nixos","libvirt","headless"],"title":"Test-Driving a NixOS VM Using Libvirt"},{"categories":["endianness"],"content":"Byte Endianness in computers has been a constant source of conflict for decades. But is there really a clear advantage to one over the other? Let\u0026rsquo;s explore together!\nOrigins The terms \u0026ldquo;Little Endian\u0026rdquo; and \u0026ldquo;Big Endian\u0026rdquo; originate from Jonathan Swift\u0026rsquo;s 1726 novel \u0026ldquo;Gulliver\u0026rsquo;s Travels\u0026rdquo;. It tells of long strife culminating in a great and costly war between the empires of \u0026ldquo;Lilliput\u0026rdquo; and \u0026ldquo;Blefuscu\u0026rdquo;, because they disagreed about which end of a boiled egg to break for eating. The \u0026ldquo;Big-Endians\u0026rdquo; went with the Emperor of Blefuscu\u0026rsquo;s court, and the \u0026ldquo;Little-Endians\u0026rdquo; rallied to Lilliput.\nThe terms were adapted for computer science in 1980 by Danny Cohen in an Internet Experiment Note titled \u0026ldquo;On Holy Wars and a Plea for Peace\u0026rdquo; , describing the conflict over the different ways of arranging bits and bytes in memory as components of larger data types. For byte-oriented data, \u0026ldquo;Little Endian\u0026rdquo; places the least significant byte of the value at the lowest address, and \u0026ldquo;Big Endian\u0026rdquo; places the most significant byte at the lowest address.\n    +0 +1 +2 +3     Big Endian 0xDE 0xAD 0xBE 0xEF   Little Endian 0xEF 0xBE 0xAD 0xDE    Both approaches have their adherents, and many flame wars erupted as rival CPU architectures, data formats, and protocols jockeyed for supremacy.\nEndianness in Meatspace The most common argument for big endian ordering in computers is that it matches the \u0026ldquo;natural order\u0026rdquo; for writing numbers. This makes it easier to read numbers in a hex dump, and is less of a cognitive load overall when humans are looking at the encoded data. But how exactly did this \u0026ldquo;natural order\u0026rdquo; come about?\nOrigins of our Numbering System Our modern numbering system has its roots in the Hindu numbering system, which was invented somewhere between the 1st and 4th century. Like the dominant writing system of the time, numbers were written right-to-left, with the lower magnitude numerals appearing in the rightmost positions (i.e. a little endian numbering system).\nThis numbering system further developed into the Hindu-Arabic decimal system around the 7th century and spread through the Arab world, being adopted into Arab mathematics by the 9th century, and then introduced to Europe via North Africa in the 10th century.\nAlthough European languages used left-to-right scripts, the numerical ordering of highest-magnitude-to-the-left was maintained in order to keep compatibility with existing mathematical texts and documents (the same thing happened when India switched to a left-to-right script). Numbers were written in big endian order in Europe and India, and remained little endian in the Arab world. Most of Asia was a mix, eventually settling on big endian.\nThus, our concept of \u0026ldquo;natural\u0026rdquo; number endianness turns out to be a cultural artifact resulting from a backward compatibility issue when using a left-to-right or top-to-bottom writing system.\nConsequences of Endianness on a Numbering System What happens when a culture adopts a particular endianness for writing numbers? Let\u0026rsquo;s have a look.\nConsider the following list of numbers:\n1 1839555 2 84734 367526634 4 495 5 2 6 20345 7 ^ 8 \u0026#34;Ones\u0026#34; digit The numerals here are ordered the way we expect them to be ordered: with the most significant digit on the left and the least significant digit on the right. All of the numbers need to be aligned along the \u0026ldquo;ones\u0026rdquo; digit so that they can be easily compared.\nTo write such numbers in a left-to-right system, we must first estimate how much room the digits could take, and then pre-emptively push to the right so that our \u0026ldquo;ones\u0026rdquo; column can remain aligned vertically (ledger pages are always right-aligned to get around this problem).\nNotice how I had to use a preformatted section with a monospaced font so that I could add a bunch of spaces to align the numbers properly!\nIn a right-to-left writing system, the \u0026ldquo;ones\u0026rdquo; digits would be aligned along the margin (to the right) and would grow outwards (left) into the free space. To better visualize this, observe the numerals mirrored for left-to-right readers:\n15559381 243748 343662576 4594 52 654302 7^ 8\u0026#34;Ones\u0026#34; digit That is, the 4th number is four-hundred-and-ninety-five, not five-hundred-and-ninety-four.\nNotice how the \u0026ldquo;ones\u0026rdquo; digits naturally align to the left margin. There\u0026rsquo;s no need to pre-emptively space anything; just write the numbers, no matter how long they get.\nEveryone remembers the hassles of doing long multiplication, right?\n1 2 4 1 6 5 2√ó 3 8 4 1 3----------- Before you even start, you have to think about how much room you\u0026rsquo;ll eventually need, because if you get it wrong you\u0026rsquo;ll end up running into the left margin:\n1 2 4 1 6 5 2 √ó 3 8 4 1 3 ----------- 4 2 4 1 6 5 5+ 9 6 6 6 0 6+ 1 9 3 3 2 0 7+ 7 2 4 9 5 8----------------- 9 9 2 8 1 7 7 6 5 But what if the numbers were written in little endian order?\n1 5 6 1 4 2 2√ó 1 4 8 3 3----------- 4 5 6 1 4 2 5+ 0 6 6 6 9 6+ 0 2 3 3 9 1 7+ 5 9 4 2 7 8----------------- 9 5 6 7 7 1 8 2 9 Now it\u0026rsquo;s no problem. The empty space is to the right, and the numbers also grow to the right! Instead of fighting the writing system order, numbers now flow with it.\nSo while everyone of course considers their culture\u0026rsquo;s number endianness to be \u0026ldquo;natural\u0026rdquo;, there is a distinct advantage to writing numbers in little endian order. And in fact, that\u0026rsquo;s the way they were first invented!\nSo What? What does this have to do with endianness in computers? We don\u0026rsquo;t have \u0026ldquo;space to the right\u0026rdquo; to be mindful of, so none of the arguments about number endianness in meatspace would seem to apply to computers at first glance. But computers and data formats do have characteristics that endianness can take advantage of.\nEndianness in Computers When dealing with computers, matching endianness to our way of visualizing numbers would be argument enough if the decision were otherwise arbitrary. Even if our system is backwards, keeping things consistent between computers and the more dominant left-to-right scripts is at least a small advantage.\nSo what exactly are the advantages each endian order enjoys in computing?\nAdvantages Detecting odd/even With big endian order, you need to check the last byte. With little endian order, you check the first byte.\n1Big Endian: 8f 31 aa 9e c2 5a 1b 3d 2 ^ 3d is odd 3 4Little Endian: 3d 1b 5a c2 9e aa 31 8f 5 ^ 3d is odd Advantage: Little Endian\nDetecting sign With little endian order, you need to check the last byte. With big endian order, you check the first byte.\n1Big Endian: 8f 31 aa 9e c2 5a 1b 3d 2 ^ 8f has sign \u0026#34;negative\u0026#34; 3 4Little Endian: 3d 1b 5a c2 9e aa 31 8f 5 ^ 8f has sign \u0026#34;negative\u0026#34; Advantage: Big Endian\nRecasting a pointer Recasting pointers involves interpreting a memory location as different types. For example, taking a memory location that contains a 32-bit integer and recasting the pointed-to value as a 16-bit integer. Recasting pointers isn\u0026rsquo;t very common in higher level languages, but it happens often in compilers and assemblers.\nWith big endian order, you must adjust the pointer\u0026rsquo;s address to match the beginning of a different sized type. With little endian, a recast degenerates into a no-op.\n1| Big Endian value 1 | Little Endian value 1 | 2| | | 3| +0 +1 +2 +3 +4 +5 +6 +7 | +0 +1 +2 +3 +4 +5 +6 +7 | 4| | | 5| | 32 bits | | | 32 bits | | 6| 00 00 00 00 00 00 00 01 | 01 00 00 00 00 00 00 00 | 7| | | 8| | 16 bits | | | 16 bits | | 9| 00 00 00 00 00 00 00 01 | 01 00 00 00 00 00 00 00 | Advantage: Little Endian\nArbitrary precision numbers and arithmetic Arbitrary precision numbers (aka big integers) are composed of integer elements in an array, which allows computing with values greater than the largest discrete integer type. Nowadays, the most common discrete type used for big integer arrays is uint32 or uint64.\n1| u64 | u64 | u64 | ... The first element contains the lowest 64 bits of data, followed by the next higher 64 bits of data, and so on (little endian ordering). The reason for this is because, as carry values spill over, it\u0026rsquo;s simply added or removed from the next element in the array.\nIf the elements were ordered big endian, you\u0026rsquo;d have to do a bunch of shifts and masks to correct everything whenever a carry occurred. The more array entries are in play, the more correction operations you\u0026rsquo;d have to do. You also have to shift everything over whenever the number grows bigger (basically the computer equivalent of shifting the whole number over when we run out of left-margin space on paper).\nAlthough this scheme can be realized with either byte order, there is an extra advantage to little endian byte ordering: If the CPU is little endian, you wouldn\u0026rsquo;t even need to care about the element size in the array because the bytes would naturally arrange themselves smoothly in little endian order across the entire array. Thus you could perform arithmetic using a single byte-by-byte algorithm, regardless of the actual element size (some little endian CPUs even have special multibyte instructions to help with this).\n   Ordering Element 0 Element 1 Byte-by-byte?     Big b7 b6 b5 b4 b3 b2 b1 b0 b7 b6 b5 b4 b3 b2 b1 b0 No   Little b0 b1 b2 b3 b4 b5 b6 b7 b0 b1 b2 b3 b4 b5 b6 b7 Yes    Advantage: Little Endian\nArbitrary length encodings Arbitrary length encodings such as VLQ allow for lightweight compression of integer values. The idea is that integers most often have the upper bits cleared, and so they don\u0026rsquo;t actually need the full integer width in order to be accurately represented.\nVLQ uses big endian ordering, which works fine when representing values up to the maximum bit width of the architecture, but once you start storing larger values that would require big int types, you run into problems:\nFor simplicity and real estate given this blog format, let\u0026rsquo;s assume a CPU with a word size of 8 bits, but the same concepts apply to bigger word sizes too. To store larger values, we use a big int type, which requires arranging the words into an array in little endian order. Since VLQ is encoded in big endian order, the first chunk marks the highest bit position, and we work our way down from there.\nFirst chunk (continuation bit \u0026ldquo;on\u0026rdquo;, so more chunks coming):\n1 W0 Bits W1 Bits 2| 7 6 5 4 3 2 1 0 | 7 6 5 4 3 2 1 0 | 3| H6 H5 H4 H3 H2 H1 H0 | | For the next chunk, we need to shift the high bits over into the next element to make room for the next set of bits (sound familiar?).\nSecond chunk (continuation bit \u0026ldquo;off\u0026rdquo;, so this is the end):\n1 W0 Bits W1 Bits 2| 7 6 5 4 3 2 1 0 | 7 6 5 4 3 2 1 0 | 3| H0 L6 L5 L4 L3 L2 L1 L0 | H6 H5 H4 H3 H2 H1 | Shifting across only one element required:\n Copying W0 to W1 Shifting W1 right by 1 Shifting W0 left by 7 Logical OR next 7 bits from the next VLQ element into W0  And this gets worse the more elements are in play.\nNow let\u0026rsquo;s see how it would work if the data were encoded using LEB128 (basically the same thing, but in little endian order):\nFirst chunk (continuation bit \u0026ldquo;on\u0026rdquo;, so more chunks coming):\n1 W0 Bits W1 Bits 2| 7 6 5 4 3 2 1 0 | 7 6 5 4 3 2 1 0 | 3| L6 L5 L4 L3 L2 L1 L0 | | For the next chunk, we split the value across two elements.\nSecond chunk (continuation bit \u0026ldquo;off\u0026rdquo;, so this is the end):\n1 W0 Bits W1 Bits 2| 7 6 5 4 3 2 1 0 | 7 6 5 4 3 2 1 0 | 3| H0 L6 L5 L4 L3 L2 L1 L0 | H6 H5 H4 H3 H2 H1 | Splitting the last VLQ element required:\n Logical OR W0 with (element\u0026laquo;7) Copy (element\u0026raquo;1) to W1  And this remains at constant complexity no matter how many elements are in play.\nBonus: It\u0026rsquo;s also possible to do arithmetic in LEB128 while it remains encoded!\nAside: Did you notice how disjointed it looks listing the high bits to the left in a left-to-right system? It would have flowed much better were they listed this way:\n1 W0 Bits W1 Bits 2| 0 1 2 3 4 5 6 7 | 0 1 2 3 4 5 6 7 | 3| L0 L1 L2 L3 L4 L5 L6 H0 | H1 H2 H3 H4 H5 H6 | Advantage: Little Endian\nVariable length encoding with a prepended length field A common encoding trick is to reserve a few bits of the encoded space to store the length of the field (low bits of the low byte if little endian, high bits of the high byte if big endian).\n1(XXXXXX LL) (XXXXXXXX) (XXXXXXXX) (XXXXXXXX) ... 2 - or - 3(LL XXXXXX) (XXXXXXXX) (XXXXXXXX) (XXXXXXXX) ... Generally with this encoding pattern, the two bits LL represent the total size of the data.\nExample:\n   LL Bytes Data Size     00 1 6 bits   01 2 14 bits   10 4 30 bits   11 8 62 bits    If this data is encoded in little endian byte order, the decoding routine is pretty easy:\n Read the first byte and extract the length field. For each byte to be read:  Read the byte into the current position. Increment current position by 1 byte.   Shift the result right 2 bits.  You can simply decode the whole thing and then shift the decoded value two bits to the right because the size field is always in the two lowest bits of the value, regardless of the size.\nIf the CPU is also little endian, the algorithm gets even simpler:\n Read the first byte to extract the length field. Read the same address again using the correct sized load instruction (recasting the pointer). Shift the result right 2 bits.  If the encoding used big endian order, the length field would be at the top of the high byte, which means that you\u0026rsquo;d need to mask out a different part of the decoded value depending on the data size.\nAdvantage: Little Endian\nConvention Most network protocols and formats until recently have been big endian (Network Byte Order).\nAdvantage: Big Endian\n\u0026ldquo;Naturalness\u0026rdquo; Binary dumps look more in line with how humans with left-to-right scripts expect to read numbers.\nAdvantage: Big Endian\nSorting unknown uint-struct blobs If you have a series of unknown blobs, and know only that the internal structure has only unsigned integers stored in descending order of significance, you can sort these blobs without knowing what the actual structure is.\nYeah, that\u0026rsquo;s a pretty rare thing, but technically it\u0026rsquo;s an advantage, and someone, somewhere is using it!\nAdvantage: Big Endian\nConclusion The big endian advantages tend to be cosmetic or convention based, or of minor usefulness. The little endian advantages offer real world performance boosts in many cases (given the right algorithm or encoding to take advantage of it).\nBig Endian Advantages  Detecting sign Convention \u0026ldquo;Naturalness\u0026rdquo; Sorting unknown uint-struct blobs  Little Endian Advantages  Detecting odd/even Recasting a pointer Arbitrary precision numbers and arithmetic Arbitrary length encodings Variable length encoding with a prepended length field  The biggest advantages go to little endian because little endian works best with \u0026ldquo;upward-growing\u0026rdquo; data (meaning data whose bits cluster to the low bits and grow into the upper empty bits). An example would be integers, which use higher and higher order bits as more digits are needed. And since integers are the most common data type in use, they offer the most opportunities.\nBig endian ordering works best with \u0026ldquo;downward-growing\u0026rdquo; data. An example would be floating point, which in some little endian architectures is actually stored in big endian byte order (although this practice is not very common due to portability issues).\n","date":"Jul 5, 2021","img":"https://www.technicalsourcery.net/images/thumbnails/endianness.png","permalink":"https://www.technicalsourcery.net/posts/on-endianness/","series":null,"tags":["endianness"],"title":"On Endianness"},{"categories":["programming"],"content":"Line lengths, like tab sizes, tabs vs spaces, and brace positioning, are among the most contentious topics in programming. This is to be expected, as predicted by Sayre\u0026rsquo;s Law : \u0026ldquo;In any dispute, the intensity of feeling is inversely proportional to the value of the issues at stake.\u0026rdquo; Naturally, contentious topics make for popular blog posts, so here we go!\nI\u0026rsquo;ve been programming for almost 40 years, 25 of those professionally. I\u0026rsquo;ve lived through many of the later seismic shifts in programming discipline, have written much code on actual 80x25 CRT terminals, and have participated in many, many contentious-yet-trivial discussions in programming.\nSince our contentious trivial topic is line width, I\u0026rsquo;d be interested to see how my recent projects have held up to the ideal line width. What\u0026rsquo;s the ideal, you ask? That\u0026rsquo;s a secret!\nLet\u0026rsquo;s have a look at my projects directory, containing around 150 semi-recent projects from the last 10 years, mostly in C, C++, Go, Java, Python, Objective-C, and Bash.\nWe\u0026rsquo;ll start in the command line. Here\u0026rsquo;s a quick shell command to print a frequency graph of line lengths for all go files:\n1find . -type f \\( -name \u0026#34;*.go\u0026#34; \\) -exec awk \u0026#39;{print length}\u0026#39; {} \\; | \\ 2 sort -n | \\ 3 uniq -c | \\ 4 awk \u0026#39;($2 \u0026gt;= 75) \u0026amp;\u0026amp; ($1 \u0026gt;= 20) {printf(\u0026#34;%3s: %s\\n\u0026#34;,$2,$1)}\u0026#39; | \\ 5 awk \u0026#39;NR==1{scale=$2/30} \\ 6{printf(\u0026#34;%-15s \u0026#34;,$0); \\ 7for (i = 0; i\u0026lt;($2/scale) ; i++) {printf(\u0026#34;=\u0026#34;)}; \\ 8printf(\u0026#34;\\n\u0026#34;)}\u0026#39; I artificially cut off line lengths under 75 (I\u0026rsquo;m only interested in longer line lengths), and anything with less than 20 occurrences. This keeps the graph small while still providing eyeball-level usefulness. The scaling is clunky (divide by 30), but it\u0026rsquo;s good enough for here.\nLegend: Line-width: count graph\n1 75: 327 ============================== 2 76: 202 =================== 3 77: 486 ============================================= 4 78: 360 ================================== 5 79: 386 ==================================== 6 80: 221 ===================== 7 81: 134 ============= 8 82: 137 ============= 9 83: 102 ========== 10 84: 119 =========== 11 85: 121 ============ 12 86: 131 ============= 13 87: 98 ========= 14 88: 85 ======== 15 89: 53 ===== 16 90: 55 ====== 17 91: 77 ======== 18 92: 117 =========== 19 93: 72 ======= 20 94: 72 ======= 21 95: 52 ===== 22 96: 55 ====== 23 97: 59 ====== 24 98: 61 ====== 25 99: 70 ======= 26100: 48 ===== 27101: 46 ===== 28102: 45 ===== 29103: 27 === 30104: 35 ==== 31105: 24 === 32106: 39 ==== 33107: 24 === 34109: 26 === 35110: 21 == 36111: 23 === Neato! That was fun, but it\u0026rsquo;s better to use the right tool for the job. Enter Gnuplot !\nGnuplot is a graph generator that can be invoked from the command line to generate pretty plots and graphs. It\u0026rsquo;s incredibly useful and powerful, but as a result has a steep learning curve. Here\u0026rsquo;s a quick gnuplot program copied from my neighbor .\nlinecounts.gnu:\n1reset 23intervals=40 4min=70 5max=150 6width=(max-min)/intervals 78hist(x,width)=width*floor(x/width)+width/2.0 910set term png 11set output \u0026#34;plot.png\u0026#34; 12set xrange [min:max] 13set yrange [0:] 14set style fill solid 1.0 15set xlabel \u0026#34;Line Width\u0026#34; 16set ylabel \u0026#34;Frequency\u0026#34; 1718plot \u0026#34;/dev/stdin\u0026#34; u (hist($1,width)):(1.0) smooth freq w boxes lc rgb\u0026#34;#2a9d8f\u0026#34; notitle I\u0026rsquo;m setting the min to 70 since I\u0026rsquo;m only interested in the longer lines, and capping at 150 because I probably have code-generated code in there somewhere, and some code generators create lines thousands of characters long.\nI\u0026rsquo;ve found in my experience that line lengths greater than 120 or so are harder to scan. Probably this has something to do with how our eyes focus. That said, the odd long line doesn\u0026rsquo;t really bother me if it\u0026rsquo;s done to preserve the structure in an eye-scan friendly way.\nTo invoke, we generate line count data the same as before, but send it to gnuplot instead:\n1find . -type f \\( -name \u0026#34;*.go\u0026#34; \\) -exec awk \u0026#39;{print length}\u0026#39; {} \\; | gnuplot linecounts.gnu This will output a file plot.png, containing the line counts of all files in all subdirs ending with .go. Change the \\( -name \u0026quot;*.go\u0026quot; \\) section to capture the file types you\u0026rsquo;re interested in.\nTooling finished! Now let\u0026rsquo;s have a look at my line widths for various languages!\nMy Projects C:  C++:  C++ really pushes the line lengths, but that\u0026rsquo;s to be expected given how verbose templates are.\nGo:  Java:  Java is slightly higher than C and Go, but overall relatively stable.\nObjective-C:  Python:  Honestly, I\u0026rsquo;d expected Python line lengths to be longer, but I guess I really made an effort to adhere to PEP-8.\nBash:  Bigger Projects Let\u0026rsquo;s have a look at some of the more popular projects out there:\nC (Linux Kernel):  Fairly strict adherence to 80 cols.\nC++ (Apple\u0026rsquo;s Swift language):  VERY strictly 80 cols.\nGo (Go compiler and standard library):  The Go compiler and library have some generated code in it, but also it looks like they don\u0026rsquo;t worry so much about line lengths.\nJava (Spring-Boot):  Spring-boot looks like it has a style around 100 or so.\nJavascript (React):  React looks like it has an ideal of 80 cols.\nPHP (Symfony):  PHP stuff in general doesn\u0026rsquo;t place much importance on line length.\nPython (Django):  Not very PEP-8, is it ;-)\nLine lengths are a contentious issue in programming, so we tend to write many rules and standards about it, even if we don\u0026rsquo;t actually follow them. But I wonder if we might be better served by a desire path approach? If we observe what people are actually doing, we can probably come up with more natural feeling line length conventions.\n","date":"May 30, 2020","img":"https://www.technicalsourcery.net/images/thumbnails/line-lengths.jpg","permalink":"https://www.technicalsourcery.net/posts/line-lengths/","series":null,"tags":["programming"],"title":"Line Lengths"},{"categories":["remote-desktop"],"content":"Have you ever wanted a persistent Linux virtual desktop that you could host anywhere and access remotely? Now you can do it, using only Ubuntu and a cheap VPS!\nI like having deterministic work environments. Disaster recovery becomes a cinch when you can just destroy and rebuild your desktop container, map your home directory back in, and continue working.\nHow it Works There are remote desktop packages that can operate on top of a purely software X window stack. We can leverage that to run in a container, where there is no hardware to access. All we need to do is install the desktop environment, and then set up the remote desktop software. This setup works in containers, virtual machines, even bare metal.\nI\u0026rsquo;ll be using Ubuntu as my base operating system, but it should be doable in other distributions as well.\nBaseline Setup The desktop environment will attempt to install bluetooth, which will break things. We pre-emptively install and disable it:\n1sudo apt update 2sudo apt install -y bluez 3sudo systemctl disable bluetooth You\u0026rsquo;ll need some preliminary tools installed:\n1sudo apt install -y software-properties-common openssh-server locales tzdata debconf Desktop Environment Next, choose a desktop environment. Due to dbus issues, only mate and lxde desktop environments work when installed this way.\n1sudo apt install -y ubuntu-mate-desktop or\n1sudo apt install -y lubuntu-desktop This step will take awhile!\nConfigure for GUI Use light-locker will interfere with remote desktop software, so remove it if it got installed:\n1sudo apt remove -y light-locker Here are some services we don\u0026rsquo;t need to have running:\n1sudo systemctl disable apport 2sudo systemctl disable cpufrequtils 3sudo systemctl disable hddtemp 4sudo systemctl disable lm-sensors 5sudo systemctl disable network-manager 6sudo systemctl disable speech-dispatcher 7sudo systemctl disable ufw 8sudo systemctl disable unattended-upgrades Some other things you may want to set up:\nTimezone: 1sudo timedatectl set-timezone \u0026#34;America/Vancouver\u0026#34; Language: 1sudo locale-gen en_US en_US.UTF-8 2sudo update-locale LANG=en_US.UTF-8 LANGUAGE=en_US:en LC_ALL=en_US.UTF-8 Keyboard Layout: 1echo \u0026#34;keyboard-configuration keyboard-configuration/layoutcode string us\u0026#34; | sudo debconf-set-selections 2echo \u0026#34;keyboard-configuration keyboard-configuration/modelcode string pc105\u0026#34; | sudo debconf-set-selections Add a User Depending on whether you\u0026rsquo;re using lxc or multipass or some other virtualization system, you may already have a user set up such as \u0026ldquo;ubuntu\u0026rdquo;. I prefer to set up my own user, like so:\n1sudo useradd -m -s /bin/bash -U -G adm,sudo mynewuser 2echo mynewuser:mynewpassword | sudo chpasswd Remember to set up allowed keys for the user if you have any.\nRemote Desktop Software X2Go X2Go is the easiest to set up. It works over ssh, which is nice and convenient, but requires a direct connection. I prefer to grab the latest from the PPA, but the default may work for you as well.\n1sudo add-apt-repository -y ppa:x2go/stable 2sudo apt install -y x2goserver x2goserver-xsession x2goclient X2Go uses ssh for communication. You\u0026rsquo;ll need to either set up allowed keys, or just for testing you could enable password authentication:\n1sudo sed -i \u0026#39;s/PasswordAuthentication no/PasswordAuthentication yes/g\u0026#39; /etc/ssh/sshd_config 2sudo service ssh restart Chrome Remote Desktop This is purely optional. You\u0026rsquo;ll still need X2Go installed to be able to set up Chrome Remote Desktop.\nFirst, download and install the debs:\n1wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb 2wget https://dl.google.com/linux/direct/chrome-remote-desktop_current_amd64.deb 3sudo apt install -y ./google-chrome-stable_current_amd64.deb ./chrome-remote-desktop_current_amd64.deb Chrome Remote Desktop will use a default screen resolution of 1600x1200, which is the wrong aspect ratio, and will result in black bands on the sides when you go fullscreen. We can just change it to whatever we want, for example 1920x1080:\n1sudo sed -i \u0026#39;s/DEFAULT_SIZE_NO_RANDR = \u0026#34;[0-9]*x[0-9]*\u0026#34;/DEFAULT_SIZE_NO_RANDR = \u0026#34;1920x1080\u0026#34;/g\u0026#39; /opt/google/chrome-remote-desktop/chrome-remote-desktop Now you\u0026rsquo;ll need to log in to the remote desktop via X2Go. You can get your virtual machine\u0026rsquo;s ip address using ip addr, then log in as the user you created earlier.\nNote: You may need to resize the virtual screen to see the menu bar.\nInside the X2Go remote desktop, do the following:\n Launch Chrome Sign in Turn on sync (or go to settings to selectively sync - even disable everything if you want) Go to the chrome store and install Chrome Remote Desktop Launch Chrome Remote Desktop and enable connections to your computer.  You should now be able to see and log in to your virtual desktop using Chrome Remote Desktop.\nConclusion Setting up a virtual desktop is a bit involved, but once you know what needs to be done, it\u0026rsquo;s not too hard to write up a script that does this automatically. I do exactly that in my Ubuntu dev environment installer .\nHappy hacking!\n","date":"Apr 3, 2019","img":"https://www.technicalsourcery.net/images/thumbnails/linux-desktop.jpg","permalink":"https://www.technicalsourcery.net/posts/virtual-linux-remote-desktop/","series":null,"tags":["remote-desktop","linux"],"title":"Virtual Linux Remote Desktop"},{"categories":["high-availability"],"content":"How important is uptime to you? How bad would it be if your services went down for 10 seconds? 10 minutes? 10 hours? 10 days? Every system has its breaking point, where the consequences become so severe that heads start rolling.\nOnce the breaking point for downtime is shorter than your worst-case time for fixing things, you need high-availability.\nWhat is High Availability? High availability is a mechanism whereby multiple redundant services collaborate to minimize interruptions. When one service goes down, another, identical service picks up the slack.\nWe see redundant systems wherever failures are too costly. Commercial airplanes have many redundant systems and sensors, as does the space shuttle and ISS. RAID arrays offer protection against data loss due to disk failures. High availability simply brings redundancy to a new level. Redundancy decreases risk, but invokes a setup and maintenance cost. Much like with insurance, the kind and amount of redundancy you need depends on your risk profile.\nI\u0026rsquo;ll talk briefly about two kinds of redundancy: network level and service level. In order to minimize costs and avoid data corruption, it\u0026rsquo;s important to know their differences:\nNetwork Level High Availability High availability at the network level involves switching a virtual IP address between different nodes that run the same service. When a node goes offline, the virtual IP is claimed by another node running the same service. This functionality can also be used to provide load balancing, where the virtual IP address floats between servers during normal operation.\nThis kind of setup has the advantage of being simple, but it doesn\u0026rsquo;t handle the failing services themselves. The downed service remains down, and must be restarted manually. If all redundant services eventually fail without someone intervening to restart them, the service goes offline completely. As well, this kind of setup has no way to detect misbehaving nodes. If a node is accepting network connections, it must be OK, even if the service inside the node is behaving badly. It\u0026rsquo;s up to the nodes themselves to monitor their own health.\nSince the management layer has no knowledge of what\u0026rsquo;s inside the nodes, all redundant services must run simultaneously, which can cause problems if they need to write to shared resources such as network filesystems. Corruption is likely, unless the services or the shared resources are carefully designed to avoid it.\nService Level High Availability High availability at the service level (clustering) is more complicated. The management layer must have knowledge about how to start, stop, and monitor services on the various nodes they\u0026rsquo;re running on. This requires a special management communication channel to the nodes (a heartbeat network ).\nThe service interfaces can be via virtual IP or some other mechanism. Nodes can run any number of services. Management can run separately, or via a quorum protocol on the nodes themselves.\nA very important distinction between the HA levels is that network level HA ensures that at least one copy of a service is running, while service level HA ensures that at most one copy of a service is running. Since only one copy of a service can run at a time, it can write to shared resources without fear of corruption. And since service level HA can directly manage services, it can fence off a misbehaving node (cut it off from all resources so that it can\u0026rsquo;t do any damage), and then kill or restart it as needed.\nThe services themselves can be anything: web servers, file systems, databases, directory services, even virtual IPs. Anything that provides access to a resource, and has a service management interface , can be managed by the cluster.\nSince management is at the service rather than node level, there\u0026rsquo;s no need to have homogenous nodes. You can have different or even multiple services on different nodes, depending on your needs and cost sensitivity, and there are numerous node configuration possibilities to choose from.\nIn Closing High availability isn\u0026rsquo;t for everyone. The turning point comes when the worry of potential downtime starts keeping you up at night. Once that happens, it\u0026rsquo;s time to look into high availability infrastructure. In future posts, I\u0026rsquo;ll write some concrete examples of network level and service level high availability you can run on Ubuntu Linux.\n","date":"Apr 1, 2019","img":"https://www.technicalsourcery.net/images/thumbnails/high-availability.jpg","permalink":"https://www.technicalsourcery.net/posts/intro-high-availability/","series":null,"tags":["high-availability"],"title":"Introduction to High Availability"},{"categories":["time"],"content":"Time is a tricky beast - quite possibly one of the trickiest things to get right in software engineering. Walk with me on a tour of time, and see why we keep getting it wrong.\nThere are two levels of time problems: advancing time and storing time. Advancing time deals with the nuances of leap years and leap seconds, and when and how and where you resolve the lost or gained time. Storing time is about how to store time values in an unambiguous way. We\u0026rsquo;ve seen plenty of posts about advancing time, so I\u0026rsquo;m going to focus on storing time in this post.\nTime Zones Time zones are deceptively simple on the surface. Every zone has a time offset from UTC in hours and minutes. Most people don\u0026rsquo;t think too deeply about them - after all, they\u0026rsquo;re just bands on a globe, right? Why should we care too much? But time zones are not that clean. Even picturing \u0026ldquo;bands on a globe\u0026rdquo; leads to the mistaken assumption that zones at the same longitude share the same time. But consider this:\n Australian Time Zones\n  Yep! Mind blown.\nThe Politics of Time Time zones are not simply a way to keep the sun shining at an appropriate hour; they are political and economic tools, and as such, follow arbitrary and ever-changing rules. A territory at +0100 one year may be +0000 the next year, and I\u0026rsquo;m not talking about daylight savings time (although that\u0026rsquo;s also a complicated political and economic subject).\nTime - at least as humans experience it - is not absolute. Time for us is meaningless without a corresponding location, and cannot even be calculated without it. At 14:00, July 1st, 1939 UTC, it was 15:20 in Amsterdam. Exactly one year later, it was 16:00. Meanwhile, in Kiev, it remained 17:00, but then switched to 16:00 in 1941, and then back to 17:00 in 1943, 17:00 and 18:00 between 1981 and 1990, and it\u0026rsquo;s 16:00 and 17:00 at the moment (but re-read this post in a decade and it may not be).\nHow often does this happen? Often enough to give you gray hairs! A Time and Place for Everything Imagine you have a daily workout schedule. Every weekday morning, you do a half hour workout from 7:30 to 8:00. If you took a week-long trip from Seattle to Berlin, that would, in absolute time, become a workout from 13:30 to 14:00. However, being human, you\u0026rsquo;re not concerned with absolute time, and would rather do your workout from 7:30 to 8:00 regardless of where you are. The absolute time changes in this case, and the local time does not.\nNow imagine you\u0026rsquo;ve got a meeting for 9:00 in Naples on the morning of August 2, 2021. Will the meeting occur at 8:00 UTC? Maybe, maybe not. Europe has voted to end daylight savings in 2021, but has left it up to each member state to decide whether to remain on daylight savings time, or go to standard time, when the changeover occurs. Depending on what Italy decides, the absolute time value of 9:00 in Naples will change. How will this affect your meeting? When will your meeting even be?\nThe issue with future events is that political changes will affect how time is interpreted. For past events, we don\u0026rsquo;t have this problem, as all changes have alreay been resolved. It doesn\u0026rsquo;t matter whether daylight savings time was in effect, or what time offset was in effect; that information is not necessary to determine the when of something in the past (although if you wanted to know what time it was locally at the time of the event, you\u0026rsquo;d of course need the location information).\nDifferent Times Since time is both political and circumstantial, we must define multiple kinds of time. RFC 5545 defines three main kinds:\n Absolute Time: A time value fixed to UTC. Fixed Time: A time value fixed to a specific time zone. Floating Time: A time value that is interpreted according to the time zone of the observer.  Time in a Bottle With all of these different ways of experiencing time, how do we store it? Ideally, you\u0026rsquo;d want to store time values in a way such that you don\u0026rsquo;t have to constantly update already stored data. It wouldn\u0026rsquo;t make sense to store floating times as UTC values, because you\u0026rsquo;d have to update your calendar database every time you changed time zones or went to/from daylight savings time. Different kinds of time have different storage requirements:\n Absolute time is always in UTC, and therefore only needs a time value. Floating time is always relative to your current time zone, and therefore also only needs a time value. Fixed time is relative to a specific time zone, and must therefore be stored along with that time zone, in values relative to that time zone.  You could in theory store fixed time in UTC, but then you\u0026rsquo;d need to sweep your database to update your times every time a time zone rule changes.\nKeeping Time Think carefully about how time affects all observers, and tailor the kind of time to whichever observer is most important to the data being captured. For example:\n An event in the past: Absolute time Your daily schedule: Floating time An appointment: Fixed time Log entries: Absolute time Deadlines (local): Probably fixed time Deadlines (international): Probably absolute time  Remember: Your goal is to store data such that it doesn\u0026rsquo;t need to be updated, because database update sweeps suck, and break, and lose data.\nA Brief Rant About IS0 8601 ISO 8601 (and RFC 3339 ) is an attempt to standardize a textual representation of time in an unambiguous manner. It mostly succeeds, except for one major problem: It only refers to time zones as numerical offsets. Why is this a problem? Future events!\nGoing back to the 2021 issue, there\u0026rsquo;s a 50% chance that 2021-08-02T09:00:00+0200 will refer to different times in Naples vs Berlin, because the location portion of the fixed time is missing! So the \u0026ldquo;time zone\u0026rdquo; information of +0200 doesn\u0026rsquo;t gain you a thing when you\u0026rsquo;re referring to future events. And even if the dev was aware enough to store Europe/Berlin along with the time, how confusing would it be if Germany were to choose standard time? Now you\u0026rsquo;d have a time containing +0200 that actually refers to a time at +0100!\nThe really annoying part is that a time without a timezone offset specifier is considered by the standard to be in local (floating) time. So you must either break the spec with a special rule that no-offset time refers to a location-based time zone that you promise to accompany all time values (i.e. the time is fixed, not floating), or you must store a confusing value for future events (plus the location-based time zone info if you want any hope of it being resolvable), or even worse, store as UTC and location, and suffer the database update sweep issue.\nWhat we really need is something like 2021-08-02T09:00:00/Europe/Berlin\nPresenting Time When presenting data, you\u0026rsquo;re best off using an established time engine rather than writing your own, because you WILL get it wrong. A good time engine is capable of converting any kind of time to any other kind. So long as you keep the kinds straight in your head, you\u0026rsquo;ll be able to present time values to your users in a sane, meaningful way.\nTime Keeps on Slipping Dealing with time is no simple task. From Y2K to leap year failures to internationalization gaffes, time - and its storage - is a source of more bugs than possibly any other data type. So the next time someone says \u0026ldquo;Easy! Just store it as UTC!\u0026rdquo;, be sure to take them quietly aside, take a firm hold, and dunk their head in a nearby toilet.\n","date":"Mar 30, 2019","img":"https://www.technicalsourcery.net/images/thumbnails/time-timezones.jpg","permalink":"https://www.technicalsourcery.net/posts/time-timezones/","series":null,"tags":["time","timezone"],"title":"Time and Timezones: Getting It Right"},{"categories":null,"content":"","date":"Jan 1, 0001","img":"","permalink":"https://www.technicalsourcery.net/offline/","series":null,"tags":null,"title":"Offline"}]